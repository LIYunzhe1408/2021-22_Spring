{"author":"李昀哲","title":"基于自然语言监督信号迁移学习视觉模型阅读报告","paragraphs":[[{"semantic_type":"NO_DETECT","text":"基于自然语言监督信号迁移学习视觉模型阅读报告","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"摘要","is_copy":false}],[{"semantic_type":"QUOTE","text":"本文灵感来源于：近期对NLP和CV领域创新项目的学习中阅读到的一篇论文 Learning Transferable Visual Models From Natural Language Supervision[1]","is_copy":false},{"semantic_type":"NO_DETECT","text":"，发表于2021年2月26日。","is_copy":false}],[{"semantic_type":"NORMAL","text":"由于在过去几年里，NLP领域取得了巨大的成果，BERT、GPT相继问世，引发了研究人员的一种想法——将NLP领域中“训练模式和下游任务分开”的方式应用到其他领域，这篇论文就开创性地将这种方法复制到了CV领域：用自然语言的监督信号，采用对比学习训练视觉模型。","is_copy":false},{"semantic_type":"NORMAL","text":"作者将这种模型命名为CLIP（Contrastive Language-Image Pre-Training）。","is_copy":false},{"semantic_type":"NORMAL","text":"CLIP具有良好的泛化性，同时能在零次学习（Zero-Shot）的情况下，对视觉的图像数据有较好的分类效果。","is_copy":false},{"semantic_type":"NORMAL","text":"在ImageNet的数据集上，CLIP可以在不用一张有标签数据的情况下，和有监督学习的ResNet-50达到相同的效果。","is_copy":true},{"semantic_type":"NORMAL","text":"采用的方法出奇的简单，但效果却出奇的好。","is_copy":true}],[{"semantic_type":"NORMAL","text":"本文就将对这篇具有开创性的论文用自己读后的观点进行解读：将从论文发表背景、研究采用的方法、研究过程中的实验、以及模型的局限等多个角度进行；","is_copy":false},{"semantic_type":"NORMAL","text":"同时将对论文中的实验用多种模型进行验证，最后进行总结和对这种开创性方法的展望。","is_copy":true}],[{"semantic_type":"NO_DETECT","text":"","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"关键词：自然语言监督信号，对比学习，视觉模型，CLIP，数据分类","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"第1章论文解读","is_copy":false}],[{"semantic_type":"NORMAL","text":"本章主要对Learning Transferable Visual Models From Natural Language Supervisions进行解读，将结合阅读后的观点介绍这项研究的背景、方法、实验以及局限性，进而对这项研究的内容和目的有整体的了解。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§1.1研究背景","is_copy":false}],[{"semantic_type":"QUOTE","text":"直接从原始的文本中预训练模型已经在过去几年的NLP领域中，取得了革命性的成果，比如：BERT[2]","is_copy":false},{"semantic_type":"NO_DETECT","text":"，GPT等。","is_copy":false},{"semantic_type":"NORMAL","text":"无论是自回归（auto-regressive）预测还是用掩码的完形填空的方式，都是自监督的训练模式，即：目标函数和下游任务是无关的，只是通过预训练得到一个泛化特征特别好的模型。","is_copy":false},{"semantic_type":"NORMAL","text":"随着计算能力的增强以及数据量的增多，模型的性能也在稳步提升，但这一套系统只是“文字进，文字出”（text-to-text)，并不是一个特殊的分类任务，模型架构也是和下游任务无关的。","is_copy":false},{"semantic_type":"NORMAL","text":"因此在研究下游任务时，不需要针对某个数据集进行特殊处理。","is_copy":false},{"semantic_type":"QUOTE","text":"比如OpenAI自己的GPT[3]","is_copy":false},{"semantic_type":"NORMAL","text":"模型就是这样的效果，能完成分类、翻译、写邮件等任务，且不需要或只需要很少特定领域的数据做微调。","is_copy":true}],[{"semantic_type":"NORMAL","text":"这些结果表明了在文本领域，利用自监督的信号训练的模型框架下，这种大规模没有标注的数据集甚至能比高质量标注过的数据集达到更好的效果。","is_copy":false},{"semantic_type":"QUOTE","text":"但在视觉领域，一般的做法还是在ImageNet[4]","is_copy":false},{"semantic_type":"NORMAL","text":"数据集上预训练一个模型。","is_copy":true},{"semantic_type":"NORMAL","text":"这就会让训练好的模型有诸多的限制那能否将NLP领域里的框架用在视觉领域里呢？","is_copy":false},{"semantic_type":"QUOTE","text":"过去20年中，相关工作有大跨度的进展，论文作者团队开发的CLIP（Contrastive Language-Image Pre-Training）模型的工作和Li et al(2017)[5]","is_copy":false},{"semantic_type":"NORMAL","text":"特别相似，都用了零次学习（Zero-Shot），但在2017年Transformer并未问世，且并没有大规模的数据集，因此这项研究的效果并不好。","is_copy":false},{"semantic_type":"QUOTE","text":"而VirTex[6]","is_copy":false},{"semantic_type":"NORMAL","text":"，ICMLM和ConVIRT等在有了强大的对比学习工具后，基于Transformer尝试过这种迁移学习的方法，和CLIP相似，不过在具体做法上还是存在区别的。","is_copy":false},{"semantic_type":"NORMAL","text":"VirTex采用自回归的预测方式做预训练，ICMLM用完型填空方式做预训练，ConVIRT和CLIP最为接近，但只在医疗图像上做了测试。","is_copy":false},{"semantic_type":"NORMAL","text":"因此，由于没有大量的数据集、没有好的自监督模型，导致精度很低，并没有引发人们关注。","is_copy":false}],[{"semantic_type":"NORMAL","text":"这些研究用文本的弱监督信号来训练有监督的模型进行分类，避免了使用有限的高质量的标注数据且提升了一定的精度，但分类的类别仍然有限，识别到的类别是固定的，一旦有新的类别，就无能为力了。","is_copy":false},{"semantic_type":"NORMAL","text":"因此没有灵活的、做零次学习（Zero-Shot）的能力。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"这些研究的方法和CLIP其实相差不大，但最大的区别是在数据集的规模上，","is_copy":false}],[{"semantic_type":"NORMAL","text":"这也是OpenAI团队在这项研究中有意去克服和优化的方向，他们构建了一个四亿数据量的数据集，模型的尝试上，选择了8种模型，从ResNet到Vision Transformer。","is_copy":false},{"semantic_type":"NORMAL","text":"测试发现，精度和模型大小基本是正相关的，在第二章也会对这项结果进行验证。","is_copy":false},{"semantic_type":"NORMAL","text":"因此使用CLIP可以根据自己采用的模型大小，大概估算出迁移学习的效果，这是一个很实用的性质。","is_copy":false},{"semantic_type":"NORMAL","text":"在大数据集和大模型的加持下，CLIP迁移学习的效果相当出色，且泛化性很好。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§1.2研究方法","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§1.2.1自然语言监督信号","is_copy":false}],[{"semantic_type":"NORMAL","text":"该团队方法的核心思路是利用自然语言的监督信号，根据前人的工作不难发现，这种思路其实并不是第一次提出，但之前的方法对于用词和用语有些不妥。","is_copy":false},{"semantic_type":"QUOTE","text":"例如Zhang et al(2020)[7]","is_copy":false},{"semantic_type":"QUOTE","text":", Gomez et al(2017)[8]","is_copy":false},{"semantic_type":"QUOTE","text":"以及Joulin et al(2016)[9]","is_copy":false},{"semantic_type":"NORMAL","text":"等人都是用到了“文本-图片”配对的方式，但他们却将这种方法描述为“无监督的”、“自监督的”和“弱监督的”。","is_copy":false},{"semantic_type":"NORMAL","text":"本论文作者的工作无非就是总结了前人的经验和方法，并扩大了模型和数据集的规模。","is_copy":false},{"semantic_type":"NORMAL","text":"核心仍旧是将文本作为训练的信号。","is_copy":true}],[{"semantic_type":"NORMAL","text":"在Transformer出现之前，NLP的模型其实并不好学，随着上下文具有语义环境的学习方式的发展，比如BERT，使得在自监督的模式之下，文本方面的监督信号拥有很多的信息资源，所以NLP训练出来的模型变得又大又好，简单、泛化性强，很适合多模态的学习。","is_copy":false}],[{"semantic_type":"NORMAL","text":"那为什么使用NLP的方法来做视觉的任务呢？","is_copy":true},{"semantic_type":"NORMAL","text":"首先，不用标注，只需要下载或爬取网络上“文本-图片”的配对，数据集是很容易得到的；","is_copy":false},{"semantic_type":"NORMAL","text":"其次，文本和视觉特征绑定在一起，学习到的特征也得到了多个维度、多模态，方便做零次学习（Zero-Shot）的迁移。","is_copy":false},{"semantic_type":"NORMAL","text":"但毫无疑问，这样的方式需要足够大的数据集。","is_copy":true}],[{"semantic_type":"NO_DETECT","text":"§1.2.2创建数据集","is_copy":false}],[{"semantic_type":"NORMAL","text":"1节末尾提到，对于已有的数据集来说，大规模的数据集存在“文不对图”的情况，例如一些图片的文本信息为相机的各类参数等，显然不是在描述图片内容，而进行清洗过后，原本数据集的规模又将大幅下降，最终的大小都和ImageNet数据集大小类似，但这样的数据集规模是不够的。","is_copy":false}],[{"semantic_type":"NORMAL","text":"因此，作者团队创建了一个足够大的数据集，收集了四亿个“文本-图片”的配对，相比于视觉领域Google的GFT还多一个亿的数据，和NLP领域的GPT-2差不多大。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§1.2.3选择高效的预训练方法","is_copy":false}],[{"semantic_type":"NORMAL","text":"视觉领域的模型都非常大，训练的代价是很高的，对于ImageNet来说，还只是预测1000个类，就已经很耗费资源了。","is_copy":false},{"semantic_type":"NORMAL","text":"对于想要达到开放视觉的分类，训练这样的系统即使是拥有大量计算资源的团队，例如本论文的OpenAI，都认为是非常惊人的训练量，是不切实际的。","is_copy":false}],[{"semantic_type":"NORMAL","text":"因此，该团队做了几个尝试，首先对于图像使用CNN，对于文本使用Transformer，通过图片来预测文本。","is_copy":false},{"semantic_type":"NORMAL","text":"但这种方法的问题在于，对于一个场景会有很多不同的解释，比如图片是一个人在打字，可能会解释为“这个人在写论文”，也可能解释为“这个人穿着蓝色的衣服”等等，会产生太多的可能性，训练就会非常慢。","is_copy":false},{"semantic_type":"NORMAL","text":"因此，该团队尝试了对比学习的方法，只需要判断图片和文本是不是一个配对，不需要去逐字逐句预测文本了，预测型的目标函数替换为了对比型的目标函数，效率直接提升了四倍，使用到了对比学习，因此命名为Contrastive Image-Language Pre-Training，对比图片和文本的预训练模型。","is_copy":false},{"semantic_type":"NORMAL","text":"如图1所示为各种尝试的性能对比。","is_copy":true}],[{"semantic_type":"NORMAL","text":"模型的伪代码如下代码块所示，思路为：需要两个编码器，图像可以是ResNet或Vision Transformer，文本可以是Text Transformer。","is_copy":false},{"semantic_type":"NORMAL","text":"输入图片和文本，通过两个编码器，得到相应特征；","is_copy":true},{"semantic_type":"NORMAL","text":"再进行多模态合并，归一化处理；","is_copy":true},{"semantic_type":"NORMAL","text":"再对特征计算cosine相似度，将用于分类，其中的t是学习参数，是需要调整的；","is_copy":true},{"semantic_type":"NORMAL","text":"最后进行交叉熵计算损失函数。","is_copy":true}],[{"semantic_type":"NORMAL","text":"由于本研究创建的数据集很大，所以训练本身不会有过拟合的问题。","is_copy":true},{"semantic_type":"NORMAL","text":"对于投射层的选择，并没有使用非线性的投射层。","is_copy":false},{"semantic_type":"NORMAL","text":"在对比学习中，非线性投射往往会比线性投射效果高10个百分点；","is_copy":false},{"semantic_type":"NORMAL","text":"而对于多模态而言，线性和非线性投射没太大影响，非线性投射只是用来适配图片单模态学习的。","is_copy":false}],[{"semantic_type":"QUOTE","text":"模型训练方面，作者在视觉模型上训练了8个模型，每个模型基于Adam优化器（Kingma & Ba, 2014)[10]","is_copy":false},{"semantic_type":"NORMAL","text":"训练了32个epochs，同时，由于数据集很大，训练十分耗时，不好调参，超参搜索过程都是在最小的ResNet-50上进行。","is_copy":false},{"semantic_type":"NORMAL","text":"最小的批量设置为32,768，非常大，因此使用了很多优化手段，如混精度训练（Micikevicius et al.","is_copy":false},{"semantic_type":"QUOTE","text":", 2017)[11]","is_copy":false},{"semantic_type":"NORMAL","text":"、梯度检查（Griewank & Walther,2000;","is_copy":true},{"semantic_type":"NO_DETECT","text":"Chen et al.","is_copy":false},{"semantic_type":"QUOTE","text":", 2016)[12]","is_copy":false},{"semantic_type":"QUOTE","text":"、半精度Adam统计(Dhariwal et al,2020)[13]","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§1.3实验","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§1.3.1零次学习（Zero-Shot)迁移","is_copy":false}],[{"semantic_type":"NORMAL","text":"只训练一个模型，之后就不再训练、不再微调，就是作者研究零次学习（Zero-Shot）迁移的动机。","is_copy":false},{"semantic_type":"NORMAL","text":"之前各种自监督或者无监督的方法，主要研究的是特征学习的能力，他们的目标是去学一种泛化性比较好的特征。","is_copy":false},{"semantic_type":"NORMAL","text":"但即使学到了很好的特征，应用到下一个任务时，仍然需要有标签的数据集去做微调，就会牵扯各种各样的问题：下游任务不好去收集数据等。","is_copy":false}],[{"semantic_type":"NORMAL","text":"然而，一旦借助文本训练了一个又大又好的模型，就可以用这个文本作为引导，去灵活地做这种零次学习（Zero-Shot）的迁移。","is_copy":false},{"semantic_type":"NORMAL","text":"至少在分类上效果都非常好。","is_copy":true}],[{"semantic_type":"NORMAL","text":"CLIP实现零次学习（Zero-Shot）的方式，可以通过图2的(2), (3)两步来解释。","is_copy":false},{"semantic_type":"NORMAL","text":"图片通过图片编码器，得到一个图片的特征；","is_copy":true},{"semantic_type":"NORMAL","text":"文本的输入，则是用户希望识别到的类别（不同于ImageNet固定的1000个类）。","is_copy":false},{"semantic_type":"NORMAL","text":"通过Prompt Engineering（后文会详细介绍，这里仅需知道是将单词变成句子），这些文本会变为句子，比如“汽车”变为“这是一张汽车的照片”。","is_copy":false},{"semantic_type":"NORMAL","text":"输入几个单词就会变成几个句子，这些句子通过文本编码器，得到相应数量的文本特征，文本特征和图像特征计算相似度，相似度再通过一层softmax，得到一个概率分布，哪一个的概率最大，相似度就最高，对应的句子大概率就是在描述这种图片。","is_copy":false},{"semantic_type":"NORMAL","text":"以ImageNet为例，有1000个类，就会生成1000个句子，相当于每输入一个图片，都会用这1000个句子去问它，看和哪个文本最接近就是哪类。","is_copy":false},{"semantic_type":"NORMAL","text":"同时这个过程并不是顺次进行，而是批次进行的，所以推理是很高效的。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§1.3.2和N-GRAMS的对比","is_copy":false}],[{"semantic_type":"NORMAL","text":"GRAMS模型就是前文提到和CLIP最相似的研究，通过表1可以看出N-GRAMS在ImageNet上仅有11.","is_copy":false},{"semantic_type":"NORMAL","text":"5%的准确率，而CLIP提升到了76.","is_copy":true},{"semantic_type":"NORMAL","text":"2%，这一结果和原版的是用128万数据样本进行训练的ResNet-50达到了同样的效果。","is_copy":false}],[{"semantic_type":"NORMAL","text":"但这种对比并不完全公平，作者使用的数据集比Visual N-Grams大了10倍，视觉方面的模型也比它大了100倍的计算能力，所有相当于训练上用了超过1000倍的资源去训练，架构上也用了2017年Visual N-Grams发表是没有提出的Transformer。","is_copy":false},{"semantic_type":"NORMAL","text":"因此作者也表达了对此前这项工作的尊重。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§1.3.3Prompt Engineering","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"本节将介绍在1.","is_copy":false},{"semantic_type":"NORMAL","text":"1中提到Prompt Engineering，这是在推理和微调时采用的一种方法，而不是在预训练阶段，所以并不需要很多的计算资源。","is_copy":false},{"semantic_type":"NORMAL","text":"这项技术顾名思义，起到了文本的提示和引导作用。","is_copy":true},{"semantic_type":"NORMAL","text":"那为什么需要文本引导的工作呢?","is_copy":true}],[{"semantic_type":"NORMAL","text":"首先是文本的多义性，只用一个单词对应就会歧义。","is_copy":true},{"semantic_type":"NORMAL","text":"比如ImageNets中construction cranes是建筑中的起重机，而单单一个crane是鹤；","is_copy":false},{"semantic_type":"NORMAL","text":"再比如remote，数据集中是遥控器的意思，但也有“遥远的”之意。","is_copy":false},{"semantic_type":"NORMAL","text":"如不加引导的输入，这样计算出的相似度就会有问题；","is_copy":false},{"semantic_type":"NORMAL","text":"其次，在预训练时，匹配的文本都是一个句子，很少是一个单词，所以通过prompt就可以使输入仅为一个单词时，转换为句子，使输入的分布差（distribution gap）得到匹配，使抽取到的特征更好。","is_copy":false}],[{"semantic_type":"NORMAL","text":"作者使用的处理方法是：将单词prompt为“a photo of a {label}.","is_copy":false},{"semantic_type":"NORMAL","text":"”，使这个label一定使名词，虽然很简单粗暴，但是很好用，做出这个修改，准确度就提升了1.","is_copy":false},{"semantic_type":"NORMAL","text":"3%，比如上述的“remote”变为“a photo of a remote”，这就消除了多义词的问题。","is_copy":false},{"semantic_type":"NORMAL","text":"同时，还能根据不同的数据集修改提示的句子，达到缩小选择空间的目的，比如：在“宠物”的数据集上测试，那就可以改为“a photo of a {label}, a type of pet”。","is_copy":false},{"semantic_type":"NORMAL","text":"作者还采用了多个（开源代码中是80个）提示模板联合分类，如图3所示，列出了部分模板。","is_copy":false},{"semantic_type":"NORMAL","text":"作者的意图是尽可能的包含所有的可能以提升准确率。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§1.3.427个数据集的实验结果","is_copy":false}],[{"semantic_type":"NORMAL","text":"图4展示了将有监督学习的ResNet-50作为基线，同零次学习（Zero-Shot）的CLIP进行27个数据集上的对比。","is_copy":false},{"semantic_type":"NORMAL","text":"可以看出，大多数结果超过了有监督学习的ResNet-50。","is_copy":true},{"semantic_type":"NORMAL","text":"通过对数据集的调研发现：对于普通的对物体分类的数据集，效果比较好。","is_copy":false},{"semantic_type":"NORMAL","text":"但对于更难的数据集（如对纹理、对图中物体计数等）效果并不好。","is_copy":false},{"semantic_type":"NORMAL","text":"我认为，对特别难的任务，零次学习（Zero-Shot）的迁移就太过苛刻了，对于人来说，没有先验知识都很难做。","is_copy":false}],[{"semantic_type":"NORMAL","text":"由于作者认为没有先验知识处理困难的问题，对CLIP有点强人所难，因此还进行了少量学习（Few-Shots）的测试，20个数据集上合并的测试结果如图5(a)所示，对比了在各个shot下的表现。","is_copy":false},{"semantic_type":"NORMAL","text":"可以看出对于一些比较难的数据集，先验知识，即Few-Shots是很有必要的。","is_copy":true},{"semantic_type":"NORMAL","text":"同时，作者还测试了用下游任务的所有数据集进行训练的效果，结果如图5 (b)所示。","is_copy":false},{"semantic_type":"NORMAL","text":"由此得出：不仅在Zero-Shot下，Few-Shots和所有数据下CLIP都完胜其他模型。","is_copy":false}],[{"semantic_type":"NORMAL","text":"在Zero-Shot, Few-Shotss和所有数据集上的测试对比工作完成后，基本衡量了模型的好坏，作者还通过实验，衡量了模型的泛化性。","is_copy":false},{"semantic_type":"NORMAL","text":"如图6可以看出，在数据有偏移时，CLIP仍旧十分稳健，而普通模型的掉点就非常严重。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"最后，由于几个测试中CLIP性能都很好，因此作者还将CLIP和人进行对比，","is_copy":false}],[{"semantic_type":"NORMAL","text":"针对Zero-Shot的情况，人以不能上网搜索来限定；","is_copy":true},{"semantic_type":"NORMAL","text":"Few-Shots的情况给人赛前看一张或两张图片。","is_copy":true},{"semantic_type":"NORMAL","text":"测试数据集采用Oxford IIT，为宠物类别的数据集，测试结果如表2所示。","is_copy":false},{"semantic_type":"NORMAL","text":"但代表性并不够，只是做了个测试，体现CLIP的强大。","is_copy":false},{"semantic_type":"NORMAL","text":"对于人和CLIP而言，分类准确度低的类二者都低，准确度高的都高。","is_copy":true},{"semantic_type":"NORMAL","text":"因此对于分类而言，人和计算机的分类方式还是有内在联系的。","is_copy":true}],[{"semantic_type":"NO_DETECT","text":"§1.4局限性","is_copy":false}],[{"semantic_type":"NORMAL","text":"我认为，这一章节才是本文最重要的一部分，虽然CLIP已经足够强大了，但一定还是有很多做不了的事情，而这些局限性，才是对于我们、对于广大的研究而言能做出提升的点，给后续研究留下更多的发展空间。","is_copy":false},{"semantic_type":"NORMAL","text":"通过作者对于自身局限性的看待，能获得很多启发。","is_copy":false}],[{"semantic_type":"NORMAL","text":"CLIP性能强，但并没有达到不可一世的地步，本文对比的只是一个基线的模型，即ResNet-50，才和它在ImageNet上打成平手。","is_copy":false},{"semantic_type":"QUOTE","text":"但相较于最新最大的Vision Transformer[14]","is_copy":false},{"semantic_type":"QUOTE","text":"和Noisy Student[15]","is_copy":false},{"semantic_type":"NORMAL","text":"，还是有十几个点的差距。","is_copy":true},{"semantic_type":"NORMAL","text":"继续加大模型和数据集，CLIP模型的性能还会上升，但对比能达到88%的模型，想要弥补十几个点的差距，要再扩大1000倍的计算资源，这显然需要新的方法。","is_copy":false}],[{"semantic_type":"NORMAL","text":"在有些数据集上（如细分类、抽象的数据集），Zero-Shot效果也并不好，低于基线的ResNet-50。","is_copy":false},{"semantic_type":"NORMAL","text":"因此，在很多数据集上，CLIP的性能和瞎猜是一样的。","is_copy":false}],[{"semantic_type":"NORMAL","text":"CLIP的泛化做得很好，对自然图像的分布偏移，模型还是相对稳健的，但如果在推理时，数据偏移的非常远，泛化效果同样也很差。","is_copy":false},{"semantic_type":"NORMAL","text":"比如在MNIST数据集上，Zero-Shot的CLIP仅有88%，一般的模型都能轻易达到99%。","is_copy":false},{"semantic_type":"NORMAL","text":"排查原因发现，预训练CLIP时，尽管有四亿个样本，由于MNIST是合成数据集，并没有一些自然的特征，所以没有一个样本和MNIST类似。","is_copy":false},{"semantic_type":"NORMAL","text":"因此，对于CLIP而言，这样的数据就在分布外，识别精度极低了。","is_copy":false}],[{"semantic_type":"NORMAL","text":"虽然CLIP可以做Zero-Shot的分类任务，但还是在用户期望的输出类别中选择，但更为直接输出是：直接生成文本输出。","is_copy":false},{"semantic_type":"NORMAL","text":"有个自然的解决想法：将生成式的目标函数和对比学习的目标函数合在一起，就有可能结合两种方法的优势。","is_copy":false}],[{"semantic_type":"NORMAL","text":"对数据的利用并不是很高效。","is_copy":true},{"semantic_type":"NORMAL","text":"测试一共用了32个epochs，每个epoch有四亿个样本，数据的利用率太低。","is_copy":false}],[{"semantic_type":"NORMAL","text":"测试时不断在已有的数据上测试，调超参数，其实已经偏离了Zero-Shot的初衷。","is_copy":false},{"semantic_type":"NORMAL","text":"因此希望未来能创建一个专门的数据集用来做Zero-Shot迁移能力的测试，就会帮助解决很多问题。","is_copy":false}],[{"semantic_type":"NORMAL","text":"CLIP所使用的文本、图像对是从网上爬取的，并没有经过严格的清洗和审查。","is_copy":false},{"semantic_type":"NORMAL","text":"因此训练出的模型很可能带有社会上的偏见，如性别、肤色、宗教等。","is_copy":false}],[{"semantic_type":"NORMAL","text":"很复杂的概念有些即使连语言都没法描述的情况，就无法处理了。","is_copy":false},{"semantic_type":"NORMAL","text":"同时在测试中还看到在Few-Shots如One-Shot和Two-Shots时，性能还不如Zero-Shot，这是很耐人寻味且不符合一般人类规律的。","is_copy":false},{"semantic_type":"NORMAL","text":"因此后期研究还将聚焦于如何使CLIP能在Zero-Shot和Few-Shots上都取得高效的表现。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"第2章论文实验结果验证","is_copy":false}],[{"semantic_type":"NORMAL","text":"本章将选取第1章中作者训练的8个视觉模型中一部分进行精度验证；","is_copy":false},{"semantic_type":"NORMAL","text":"并对论文中测试结果较好的模型，网络上任意选择图片进行分类准确度的测试。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§2.1不同模型同一图片、给定类，分类精度验证","is_copy":false}],[{"semantic_type":"NORMAL","text":"代码如下所示，其中红色字体部分为加载模型的替换部分；","is_copy":false},{"semantic_type":"NORMAL","text":"划线部分为可修改的期望识别到的类。","is_copy":true}],[{"semantic_type":"NORMAL","text":"对于不同模型，同一图片、给定类，用图7 (a)进行测试。","is_copy":true},{"semantic_type":"NORMAL","text":"这里的加载模型，选择RN50, RN50x16, ViT-B/16，模型规模依次增大。","is_copy":false},{"semantic_type":"NORMAL","text":"测试图为小笼包（Shanghai Dumpling），给定类为馄饨、小笼包、馒头、面粉和上海。","is_copy":false},{"semantic_type":"NORMAL","text":"测试结果如表 所示，在小规模的模型RN50上，概率最高的是馒头（Steamed Bun)，显然分类出错；","is_copy":false},{"semantic_type":"NORMAL","text":"随着模型规模的增大，概率为小笼包的占比逐渐增大，在ViT-B/16上精度最高，为92.","is_copy":true},{"semantic_type":"NORMAL","text":"68%，基本满足论文中提到的精度和模型规模正相关。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§2.2同一模型、图片不同给定类，分类准确度验证","is_copy":false}],[{"semantic_type":"NORMAL","text":"第二个验证实验为对同一图片、模型，给定有细微区别的不同的两个类，测试分类准确度。","is_copy":false},{"semantic_type":"NORMAL","text":"测试用图为图7 (b) 紫馒头（Purple Bun），给定类 (a) 中包含“紫馒头”类，测试结果如表4 (a) 所示，分类准确；","is_copy":false},{"semantic_type":"NORMAL","text":"给定类 (b) 中，不包含“紫馒头”，改为“馒头”和“紫色”，测试结果如表4 (b) 所示，这次分类的最大值给到了“紫色”(Purple)，虽然并没有错，但是否将它分为“馒头”会更合理些呢？","is_copy":false}],[{"semantic_type":"NORMAL","text":"对于“红包”图片也做了类似的测试，其中干扰项为“Red”和“Envelope”，最后的结果也将最大值给到了“红色”(Red)。","is_copy":false},{"semantic_type":"NORMAL","text":"因此引发思考：是否模型在无法确定准确类的情况下，优先根据颜色分类呢？","is_copy":false},{"semantic_type":"NORMAL","text":"这也值得更深入的研究。","is_copy":true}],[{"semantic_type":"NO_DETECT","text":"第3章总结与展望","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"§3.1本文总结","is_copy":false}],[{"semantic_type":"NORMAL","text":"本文通过将“NLP领域预训练模型使之与下游任务无关”的思想，开创性地复制到了视觉领域，目的在于方法的迁移和使模型获得良好的泛化性。","is_copy":false},{"semantic_type":"NORMAL","text":"虽然也有很多的局限性，但总体而言，在多个数据集上的效果确实不错。","is_copy":false},{"semantic_type":"NORMAL","text":"预训练采用了对比学习的方式，在大规模数据集和大模型的加持下性能较好且有不错的泛化性，提升空间也很大。","is_copy":false},{"semantic_type":"NORMAL","text":"核心在于打破了固定种类标签的范式，在收集数据集和训练模型时，不用再预定义各种固定的类。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"简而言之，在以下三个角度，这篇论文研究都很出色：","is_copy":false}],[{"semantic_type":"NORMAL","text":"新颖度：打破了视觉领域固定标签的做法，彻底放飞了视觉模型的训练过程；","is_copy":false}],[{"semantic_type":"NORMAL","text":"有效性：创建的数据集规模大，模型分类效果好、泛化性可观，在某种数据集    下比人类分类的性能还好；","is_copy":false}],[{"semantic_type":"NORMAL","text":"解决问题大小：一个模型解决了大部分的分类任务，光是图像数据的分类，就是一个宏观上的大问题了。","is_copy":false}],[{"semantic_type":"NORMAL","text":"因此，这篇论文的学习、研究价值是很高的，也为我创新项目中涉及的图像分类任务提供了一个新思路。","is_copy":false},{"semantic_type":"NORMAL","text":"也引发了我对如何进一步优化模型局限性的思考。","is_copy":true}],[{"semantic_type":"NO_DETECT","text":"§3.2展望","is_copy":false}],[{"semantic_type":"NORMAL","text":"该论文为计算机领域的研究提供了一个新思路，不仅打通了NLP领域和视觉领域的方法迁移，更打通了计算机各技术领域间的壁垒，鼓励技术间的触类旁通。","is_copy":false},{"semantic_type":"NORMAL","text":"计算机不仅可以和其他学科开展交叉研究，用其他学科领域知识（如脑科学等）引导计算机领域的工作，计算机专业本身的各个技术领域也能交叉引导其他技术领域的发展。","is_copy":false},{"semantic_type":"NORMAL","text":"就我个人而言，想要实时了解最前沿的其他各个技术领域的知识并不容易，不仅涉及很多技术上的难点，还涉及获取上的困难。","is_copy":false},{"semantic_type":"NORMAL","text":"在本科阶段，我认为课程中安排这种精读论文、辅以自己根据论文进行代码应用和实验的方式非常好，虽然精读的量并不大，但提供了沉下心读论文的机会，也对技术细节有了大致的了解。","is_copy":false},{"semantic_type":"NORMAL","text":"今后课程结束，会将其作为习惯，定期精读前沿论文。","is_copy":false}],[{"semantic_type":"NORMAL","text":"计算机的工作往往是模仿人类、帮助人类完成各项枯燥、危险、高难度的工作，因此对计算机技术的研究往往需要结合对人类活动特点的研究，比如对图像分类而言，如果人类得到一句文本的提示，很自然地会在图像分类时会加大准确率。","is_copy":false},{"semantic_type":"NORMAL","text":"这种想法通常是自然的，但如何将这种自然的想法应用到技术领域中，就是更高阶的思想和处理方式了。","is_copy":false},{"semantic_type":"NORMAL","text":"相信今后会有更多技术得到这种人类活动的启发。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"致谢","is_copy":false}],[{"semantic_type":"NORMAL","text":"在本次课程中，虽然由于疫情不能在教室里和同学老师相见，但课程的形式保障了教学质量，线上课堂中我不仅学习、了解到了大数据的理论知识和各种方法，更得到了沉下心阅读前沿论文的机会，真正实现了从理论到实践。","is_copy":false},{"semantic_type":"NORMAL","text":"作为计算机专业的同学，学习是常伴吾身的，时刻不能松懈，但惭愧的是，直到这次课程才真正研读第一篇论文。","is_copy":false},{"semantic_type":"NORMAL","text":"不过我相信这会是一个好的开始，非常感谢王健嘉老师和计算机学院开设此课程，虽有不能面对面相见的遗憾，却充满收获知识的喜悦。","is_copy":false}],[{"semantic_type":"NORMAL","text":"本论文的完成不仅标志着本课程的结束，也标志着我得到启迪的新学习之路的开始，生活中离不开大数据，虽然课程中仅对相关概念、技术简要的进行了介绍，但师傅领进门，修行靠自身，相信会在未来的学习生活中不断提升对于“大数据”的见解。","is_copy":false},{"semantic_type":"NORMAL","text":"疫情正在不断好转，也相信在不远的未来，就能在校园里相见。","is_copy":false}],[{"semantic_type":"NO_DETECT","text":"","is_copy":false}]],"uuid":"37227f3d-2b70-485a-b53b-963ffa09e5b4","version":"v1.0"}