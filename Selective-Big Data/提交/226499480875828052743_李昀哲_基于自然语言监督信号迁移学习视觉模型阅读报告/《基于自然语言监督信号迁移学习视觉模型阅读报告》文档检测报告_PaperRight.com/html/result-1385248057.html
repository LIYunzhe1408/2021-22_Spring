<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>无标题文档</title>
    <link href="img/style.css" rel="stylesheet" type="text/css" media="all" />
</head>

<body>
	<div class="mainbody result">
		<strong class="title">原文句子<a href="#modifyAdvise">（查看句子修改意见）</a></strong>
    	<div class="p source">
        	图片通过图片编码器，得到一个图片的特征；
        </div>
        
        <strong class="title">片段位置图</strong>
    	<p>
        	<img src="img/localimg_1385248057.png"/>
        </p>
        
        <strong class="title">相似结果</strong>
        
        <table class="detail">
        	<tbody>
	            <tr>
	            	<td valign="top" class="result">
									<div class="p">
						        		<b>相似片段 1：</b> 部分:1)<em>图片特征编码器;2)文本特征编码器;3)组合图片和文本特征的 TIRG 模块。首先,通过图片特征编码器得到图片特征,通过文本特征编码器得到文本特征;然后,通过 TIRG模块“修改”源图片特征</em>
						        	</div>
									<table class="detail none" border="0">
										<tr><td width="60">篇名</td><td>《基于语言描述的细粒度美妆图片排序》</td></tr>
										<tr><td>对比库</td><td>
													中国学术期刊数据库</td></tr>
								                  		<tr><td>来源信息</td><td>
																期刊名称（计算机科学）
																作者（姚林丽,陈师哲,金琴）
																作者单位（中国人民大学信息学院 北京 100872）
																日期（2020-12-01）
									                  	</td></tr>
																					<tr>
											<td>相似率</td>
											<td>
													87.5%
														<span class="autotype">（高度相似）</span>
											</td>
										</tr>
														<tr>
															<td>文献溯源</td>
															<td>
																<span class="baiduxueshu">百度学术</span>
																<a href="http://xueshu.baidu.com/s?wd=%E5%9F%BA%E4%BA%8E%E8%AF%AD%E8%A8%80%E6%8F%8F%E8%BF%B0%E7%9A%84%E7%BB%86%E7%B2%92%E5%BA%A6%E7%BE%8E%E5%A6%86%E5%9B%BE%E7%89%87%E6%8E%92%E5%BA%8F&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
															</td>
														</tr>
									</table>
									<div class="p">
						        		<b>相似片段 2：</b>的TIRG模块.首先,<em>通过图片特征编码器得到图片特征，通过文本特征编码器得到文本特征；然后，通过TIRG模块“修改”源图片特征得到组合特征；最后,计算组合特征和待检索图片特征</em>之间的匹配分数,以检索最
						        	</div>
									<table class="detail none" border="0">
										<tr><td width="60">篇名</td><td>《基于语言描述的细粒度美妆图片排序》</td></tr>
										<tr><td>对比库</td><td>
													中国学术期刊数据库</td></tr>
								                  		<tr><td>来源信息</td><td>
																期刊名称（计算机科学）
																作者（姚林丽,陈师哲,金琴）
																作者单位（中国人民大学信息学院,北京100872）
																日期（2020-12-01）
									                  	</td></tr>
																					<tr>
											<td>相似率</td>
											<td>
													87.5%
														<span class="autotype">（高度相似）</span>
											</td>
										</tr>
														<tr>
															<td>文献溯源</td>
															<td>
																<span class="baiduxueshu">百度学术</span>
																<a href="http://xueshu.baidu.com/s?wd=%E5%9F%BA%E4%BA%8E%E8%AF%AD%E8%A8%80%E6%8F%8F%E8%BF%B0%E7%9A%84%E7%BB%86%E7%B2%92%E5%BA%A6%E7%BE%8E%E5%A6%86%E5%9B%BE%E7%89%87%E6%8E%92%E5%BA%8F&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
															</td>
														</tr>
									</table>
									<div class="p">
						        		<b>相似片段 3：</b>和<em>图片编码特征的网络模块。假设输入的问题经过问题编码器后的输出为<?，输人的图片经过图片编码器后的输出为 tV清景动态记忆模块通过？和 r 得到问题和图片</em>之间的联系。该模块利用门控循环单元
						        	</div>
									<table class="detail none" border="0">
										<tr><td width="60">篇名</td><td>《基于动态记忆网络的智能视觉问答系统的设计与实现》</td></tr>
										<tr><td>对比库</td><td>
													中国学术期刊数据库</td></tr>
								                  		<tr><td>来源信息</td><td>
																期刊名称（仪表技术）
																作者（吴玥[1,2],高会议,陈雷,曾明昭[2,3],万莉）
																作者单位（安徽大学物质科学与信息技术研究院,安徽合肥230601,中国科学院合肥智能机械研究所,安徽合肥230031,中国科学技术大学,安徽合肥230026）
																日期（2020-05-01）
									                  	</td></tr>
																					<tr>
											<td>相似率</td>
											<td>
													87.5%
														<span class="autotype">（高度相似）</span>
											</td>
										</tr>
														<tr>
															<td>文献溯源</td>
															<td>
																<span class="baiduxueshu">百度学术</span>
																<a href="http://xueshu.baidu.com/s?wd=%E5%9F%BA%E4%BA%8E%E5%8A%A8%E6%80%81%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E6%99%BA%E8%83%BD%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
															</td>
														</tr>
									</table>
									<div class="p">
						        		<b>相似片段 4：</b>，整个网络结构中的损失函数采用的是简单的空间重构损失，整个网络的主要目的是根据自<em>编码器训练出一个初始的处理受损图片的网络，通过将带掩模 mask的图片输入到训练完成的自编码器中，得到一个</em>粗略的修复结果。然后将粗修复结果输入第二阶段的神经网络进行处理。
						        	</div>
									<table class="detail none" border="0">
										<tr><td width="60">篇名</td><td>《基于GAN的多尺度注意力机制图像复原》</td></tr>
										<tr><td>对比库</td><td>
													中国学位论文全文数据库</td></tr>
							                  			<tr><td>来源信息</td><td>
																作者（张彭杨）
																学校（武汉大学）
																分类（微电子学与固体电子学）
																学位（硕士）
																日期（2021-01-01）
							                  			</td></tr>
																					<tr>
											<td>相似率</td>
											<td>
													87.5%
														<span class="autotype">（高度相似）</span>
											</td>
										</tr>
														<tr>
															<td>文献溯源</td>
															<td>
																<span class="baiduxueshu">百度学术</span>
																<a href="http://xueshu.baidu.com/s?wd=%E5%9F%BA%E4%BA%8EGAN%E7%9A%84%E5%A4%9A%E5%B0%BA%E5%BA%A6%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%8E%9F&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
															</td>
														</tr>
									</table>
									<div class="p">
						        		<b>相似片段 5：</b>用上一章节所设计的光照增强网络，经过卷积神经网络解码器重建<em>得到相应的光照增强后的图片。在此阶段，使用与之前提到的本研究所设计的三种卷积神经网络编码器，在此命名为 EH，提取光照增强后生成的亮光图片的特征</em>
						        	</div>
									<table class="detail none" border="0">
										<tr><td width="60">篇名</td><td>《针对视觉定位的暗光条件下图像检索方法研究》</td></tr>
										<tr><td>对比库</td><td>
													中国学位论文全文数据库</td></tr>
							                  			<tr><td>来源信息</td><td>
																作者（蔡宁馨）
																学校（哈尔滨工业大学）
																分类（机械电子工程）
																学位（硕士）
																日期（2021-01-01）
							                  			</td></tr>
																					<tr>
											<td>相似率</td>
											<td>
													75%
														<span class="autotype">（高度相似）</span>
											</td>
										</tr>
														<tr>
															<td>文献溯源</td>
															<td>
																<span class="baiduxueshu">百度学术</span>
																<a href="http://xueshu.baidu.com/s?wd=%E9%92%88%E5%AF%B9%E8%A7%86%E8%A7%89%E5%AE%9A%E4%BD%8D%E7%9A%84%E6%9A%97%E5%85%89%E6%9D%A1%E4%BB%B6%E4%B8%8B%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
															</td>
														</tr>
									</table>
									<div class="p">
						        		<b>相似片段 6：</b>然后这些生成的、没有遮挡的图像块将会和原始被遮挡的人脸<em>图片进行融合得到新的没有遮挡的人脸图像。这个新的人脸图像将作为深度特征点回归器网络的部分输入，通过</em>对人脸外观和人脸形状增量之间的映射关系进行更
						        	</div>
									<table class="detail none" border="0">
										<tr><td width="60">篇名</td><td>《无约束人脸对齐算法研究》</td></tr>
										<tr><td>对比库</td><td>
													中国学位论文全文数据库</td></tr>
							                  			<tr><td>来源信息</td><td>
																作者（万俊）
																学校（武汉大学）
																分类（计算机应用技术）
																学位（博士）
																日期（2019-01-01）
							                  			</td></tr>
																					<tr>
											<td>相似率</td>
											<td>
													75%
														<span class="autotype">（高度相似）</span>
											</td>
										</tr>
														<tr>
															<td>文献溯源</td>
															<td>
																<span class="baiduxueshu">百度学术</span>
																<a href="http://xueshu.baidu.com/s?wd=%E6%97%A0%E7%BA%A6%E6%9D%9F%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
															</td>
														</tr>
									</table>
									<div class="p">
						        		<b>相似片段 7：</b>结构（1）内容/风格<em>编码器由于 FMGAN 将图片的内容与风格解开，所以编码器包含内容编码器与风格编码器。内容编码器需要保存图片的大部分特征，编码后得到</em>高维复杂的内容向量，其网络结构和第二章的变分自动
						        	</div>
									<table class="detail none" border="0">
										<tr><td width="60">篇名</td><td>《基于GAN的人脸表情与妆容迁移方法研究》</td></tr>
										<tr><td>对比库</td><td>
													中国学位论文全文数据库</td></tr>
							                  			<tr><td>来源信息</td><td>
																作者（陈卓）
																学校（武汉理工大学）
																分类（电子科学与技术）
																学位（硕士）
																日期（2019-01-01）
							                  			</td></tr>
																					<tr>
											<td>相似率</td>
											<td>
													75%
														<span class="autotype">（高度相似）</span>
											</td>
										</tr>
														<tr>
															<td>文献溯源</td>
															<td>
																<span class="baiduxueshu">百度学术</span>
																<a href="http://xueshu.baidu.com/s?wd=%E5%9F%BA%E4%BA%8EGAN%E7%9A%84%E4%BA%BA%E8%84%B8%E8%A1%A8%E6%83%85%E4%B8%8E%E5%A6%86%E5%AE%B9%E8%BF%81%E7%A7%BB%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
															</td>
														</tr>
									</table>
									<div class="p">
						        		<b>相似片段 8：</b>同样尺寸的大小，实现<em>图片重构。本文基于CAE方法，利用其编码器结构对路面原始图像进行数据降维并得到图片的特征空间，嵌入聚类网络，实现路面图片的无监督深度聚类；利用其解码器结构将图片重构，获得新的图片</em>
						        	</div>
									<table class="detail none" border="0">
										<tr><td width="60">篇名</td><td>《基于卷积自编码的沥青路面目标与裂缝智能识别》</td></tr>
										<tr><td>对比库</td><td>
													中国学术期刊数据库</td></tr>
								                  		<tr><td>来源信息</td><td>
																期刊名称（中国公路学报）
																作者（侯越,陈逸涵,顾兴宇,茅荃,曹丹丹,WANG Lin-bing,荆鹏）
																作者单位（北京工业大学北京市交通工程重点实验室,北京100124,东南大学交通学院,江苏南京210096,江苏现代路桥有限责任公司,江苏南京210096,弗吉尼亚理工大学土木工程与环境工程系,弗吉尼亚黑堡VA 24061）
																日期（2020-10-01）
									                  	</td></tr>
																					<tr>
											<td>相似率</td>
											<td>
													75%
														<span class="autotype">（高度相似）</span>
											</td>
										</tr>
														<tr>
															<td>文献溯源</td>
															<td>
																<span class="baiduxueshu">百度学术</span>
																<a href="http://xueshu.baidu.com/s?wd=%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E8%87%AA%E7%BC%96%E7%A0%81%E7%9A%84%E6%B2%A5%E9%9D%92%E8%B7%AF%E9%9D%A2%E7%9B%AE%E6%A0%87%E4%B8%8E%E8%A3%82%E7%BC%9D%E6%99%BA%E8%83%BD%E8%AF%86%E5%88%AB&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
															</td>
														</tr>
									</table>
									<div class="p">
						        		<b>相似片段 9：</b>可以在图像修复中取得良好的效果，因此对残缺<em>图片的编码器，我们选择采用与其类似的结构。残缺图片的编码器在第二层卷积和第四层卷积中通过下采样将特征图大小压缩为原始大小的 1/16，之后通过</em>连续的膨胀卷积来
						        	</div>
									<table class="detail none" border="0">
										<tr><td width="60">篇名</td><td>《基于条件生成对抗网络的图像修复方法研究》</td></tr>
										<tr><td>对比库</td><td>
													中国学位论文全文数据库</td></tr>
							                  			<tr><td>来源信息</td><td>
																作者（郝鸣阳）
																学校（中国矿业大学(江苏),中国矿业大学）
																分类（计算机技术）
																学位（硕士）
																日期（2019-01-01）
							                  			</td></tr>
																					<tr>
											<td>相似率</td>
											<td>
													75%
														<span class="autotype">（高度相似）</span>
											</td>
										</tr>
														<tr>
															<td>文献溯源</td>
															<td>
																<span class="baiduxueshu">百度学术</span>
																<a href="http://xueshu.baidu.com/s?wd=%E5%9F%BA%E4%BA%8E%E6%9D%A1%E4%BB%B6%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
															</td>
														</tr>
									</table>
	                </td>
	            </tr>
	        </tbody>
        </table>
        	<a name="modifyAdvise"></a>
			<div class="p"
				style="background: #FFFFE1; border: 1px dashed #FF9797;">
				<p style="font-size: 14px; font-weight: bold;">※ 片段修改建议 ※</p>
				<b>近似词参考：</b><ul type='1'><li>通过：经由过程 </li><li>得到：获得 </li><li>特征：特点 特性 </li></ul><p><b>系统自动生成语句：</b>图片<u>经由过程</u>图片编码器，<u>获得</u>一个图片的<u>特点</u>；</p><p class='gray'>注：本片段修改建议为系统自动生成，仅供参考。	</p>
			</div>
	</div>
</body>
</html>
